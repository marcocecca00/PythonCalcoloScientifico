{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Convolutional Neural Networks**\n",
    "## *Imagine Recognition*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una delle applicazioni più diffuse del **deep learning** riguarda il *riconoscimento degli oggetti* presenti all'interno di un'immagine. In tal senso, è necessario introdurre due ulteriori layer, che rappresentano la base per le cosiddette **convolutional neural network**.\n",
    "\n",
    "Queste reti (che chiameremo per brevità **CNN**) sono specializzate nel lavorare su immagini, ma possono anche essere usate per segnali monodimensionali (come la voce) o tridimensionali (come le nuvole di punti).\n",
    "\n",
    "Le CNN assumono una rilevanza fondamentale nel moderno deep learning: è grazie a loro se il campo del deep learning è diventato mainstream nel mondo della ricerca, il che ha portato ad un interesse e, conseguentemente, ad avanzamenti impensabili in un ridottissimo lasso di tempo di soli dieci anni. Oggigiorno, le CNN vengono utilizzate in ogni ambito che preveda l'*elaborazione di dati bidimensionali*, dal *riconoscimento facciale* all'*individuazione* e caratterizzazione delle targhe degli autoveicoli in transito; conoscerle, quindi, è imprescindibile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Layer Convoluzionale**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I **layers convoluzionali** sono alla base del funzionamento delle CNN.\n",
    "\n",
    "Il concetto alla base di questo tipo di layer è la **convoluzione** che, nel contesto del deep learning, è un'*operazione lineare che prevede la moltiplicazione di un insieme di pesi*, chiamato **filtro**, con una piccola porzione (o *finestra*) dell'immagine considerata, seguita ovviamente da una funzione di attivazione. Questo processo è analogo a quello che avviene in una tradizionale rete neurale.\n",
    "\n",
    "Il filtro ha dimensioni volutamente *inferiori* rispetto a quelle dell'immagine da *convolver*e, tipicamente nell'ordine di $3x3$ o $5x$ pixel; la convoluzione del filtro per ogni finestra dell'immagine è inoltre assimilabile ad un *prodotto scalare*, per cui viene restituito sempre un unico valore per ogni finestra convoluta. In tal senso, il filtro viene \"fatto scorrere\" *dall'alto in basso*, *da sinistra verso destra*, anche su finestre sovrapposte, che scorrono quindi a passo di un pixel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tecnicamente, quindi, l'operazione definita come \"convoluzione\" è in realtà una cross-correlazione.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applicare sistematicamente lo *stesso filtro* su tutte le finestre possibili dell'immagine, anche sovrapposte, è un'idea alquanto potente: infatti, un filtro viene opportunamente *tarato* per riconoscere uno specifico tipo di feature, come un *bordo* o una *forma*, che potrà essere trovata ovunque nell'immagine grazie allo scorrimento, ottenendo la cosiddetta **invarianza alla traslazione**.\n",
    "\n",
    "Abbiamo accennato al fatto che l'output dell'applicazione di un filtro su di una finestra dell'immagine è un prodotto scalare. Di conseguenza, man mano cheil filtro scorre, viene creato un *array bidimensionale* di valori, che viene indicato come **mappa delle feature**, o **feature map**. Sarà proprio questa, e non l'immagine iniziale, ad essere passata al layer successivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Layer di Pooling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbiamo visto come i layer convoluzionali creino delle *feature map* che \"sintetizzano\" la presenza di determinate feature all'interno di un input. Un limite di queste mappature sta però nel fatto che registrano la posizione precisa della feature individuata all'interno dell'input: ciò significa quindi che anche *piccole variazioni nella posizione di una feature risulterà in una feature map completamente differente*, il che comporta un'estrema sensibilità della rete neurale a piccole trasformazioni dell'immagine di input.\n",
    "\n",
    "Per risolvere questo problema, si utilizza un approccio chiamato **sottocampionamento**: in pratica, si ricava una versione a *più bassa risoluzione del segnale di ingresso*, evidenziando di conseguenza gli elementi più importanti, e scartando i piccoli dettagli non rilevanti nel task di classificazione. Per far questo, viene utilizzato un **layer di pooling**, applicato *a cascata rispetto a quello convoluzionale*.\n",
    "\n",
    "Il *layer di pooling* non fa altro che applicare un filtro, di solito di dimensioni $2x2$ e con un passo di $2$ pixel (quindi senza sovrapposizioni), che applica una funzione di sottocampionamento, scegliendo quindi un unico pixel tra quelli presenti nel filtro. Due *funzioni di pooling* molto comuni sono le seguenti:\n",
    "\n",
    "- **average pooling**: questo filtro associa ad ogni finestra dell'immagine in input il valore medio presente nella finestra;\n",
    "\n",
    "- **max pooling**: questo filtro associa ad ogni finestra dell'immagine in input il valore massimo presente nella finestra.\n",
    "\n",
    "Ottenendo quindi una versione \"sottocampionata\" dell'input, si raggiunge la cosiddetta **invarianza a traslazioni locali**, ovvero una sorta di \"insensibilità\" del modello a traslazioni o rotazioni di entità minima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Esercizi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Es 11.0**\n",
    "\n",
    "Creare un modello di rete neurale composto in questo modo:\n",
    "\n",
    "Layer (type) | Output Shape | Param # \n",
    ":-----: | :--------: | :-----:\n",
    "**conv_1 (Conv2D)**   |  (None, 30, 30, 32)  | 896\n",
    "**pooling_1 (MaxPooling2D)**  | (None, 15, 15, 32)  | 0\n",
    "**conv_2 (Conv2D)**  | (None, 13, 13, 32)  | 9248\n",
    "**dropout (Dropout)**   |  (None, 13, 13, 32)   | 0\n",
    "**flatten (Flatten)**  |  (None, 5408)   | 0\n",
    "**classification (Dense)**  | (None, 10)  | 54090\n",
    "\n",
    "Questo modello deve essere in grado di classificare le immagini presenti nel dataset [CIFAR10](https://keras.io/api/datasets/cifar10/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Si è verificato un arresto anomalo del kernel durante l'esecuzione del codice nella cella attiva o in una cella precedente. Esaminare il codice nelle celle per identificare una possibile causa dell'errore. Per altre informazioni, fare clic su <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a>. Per altri dettagli, vedere Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(\n",
    "            shape=(32, 32, 3),\n",
    "            name='input'),\n",
    "        keras.layers.Conv2D(\n",
    "            32,\n",
    "            (3, 3),\n",
    "            activation='relu',\n",
    "            name='conv_1'),\n",
    "        keras.layers.MaxPool2D(\n",
    "            pool_size=(2, 2),\n",
    "            name='pooling_1'),\n",
    "        keras.layers.Conv2D(\n",
    "            32,\n",
    "            (3, 3),\n",
    "            activation='relu',\n",
    "            name='conv_2'),\n",
    "        keras.layers.Dropout(\n",
    "            0.5,\n",
    "            name='dropout'),\n",
    "        keras.layers.Flatten(name='flatten'),\n",
    "        keras.layers.Dense(\n",
    "            10,\n",
    "            activation='softmax',\n",
    "            name='classification')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=['acc'])\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    epochs=25,\n",
    "    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "    range(1, 26),\n",
    "    history.history['acc'],\n",
    "    label='Accuracy')\n",
    "plt.plot(\n",
    "    range(1, 26),\n",
    "    history.history['val_acc'],\n",
    "    label='Validation accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2024b47f9e0e00785bf7b410773834da4047a250e58841a8c9925163fbfa3efc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
