{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Metriche**\n",
    "## *Metriche per classificatori e regressori e Tuning di soglia*\n",
    "Definizione della *soglia di decisone*, *accuratezza*, *metriche fondamentali* e *tuning della soglia di decisione*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Soglia di decisione**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideriamo il caso dello *spam detector*. Un modello di regressione logistica che restituisca una probabilità $p=0.999$ ci sta dicendo che, molto probabilmente, questo è di spam; di converso, se il modello restituisce $p=0.003$ allora è molto probabile che il messaggio non sia spam. Cosa accade però nel caso in cui $p=0.505$ ?\n",
    "\n",
    "Quindi per passare da una probabilità ad una classe sia necessario definire una **soglia di decisione**: un valore oltre questa soglia indicherà, ad esempio, che la mail ricevuta è di spam, mentre uno al di sotto della soglia ci suggerirà che non lo è.\n",
    "\n",
    "Ovviamente, la tentazione potrebbe essere quella di presupporre che la soglia di decisione sia sempre pari a 0.5 questo, ovviamente, non è vero, in quanto la soglia dipende dal problema, ed è un valore che bisogna stabilire in base al problema affrontato. Introduciamo alcune metriche che possono essere usate in tal senso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Metriche per i classificatori**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuiamo a concentrarci sul caso della classificazione dello spam, ed introduciamo il concetto di *classe positiva* e *classe negativa*.\n",
    "\n",
    "In particolare, la classe positiva sarà rappresentata da tutte le mail di spam, mentre la classe negativa sarà rappresentata dalle mail non spam. In tal senso, le predizioni del modello potranno essere di quattro tipi:\n",
    "\n",
    "- nel primo caso, il modello classificherà correttamente una mail di spam. In questo caso, si parla di vero positivo, o **true positive (TP)**;\n",
    "- nel secondo caso, il modello classificherà correttamente una mail legittima. In questo caso, si parla di vero negativo, o **true negative (TN)**;\n",
    "- nel terzo caso, il modello classificherà una mail di spam come legittima. In questo caso, si parla di falso negativo, o **false negative (FN)**;\n",
    "- nel quarto caso, il modello classificherà una mail legittima come di spam. In questo caso, si parla di falso positivo, o **false positive (FP)**.\n",
    "\n",
    "In pratica, un **TP (TN)** si ha quando *il modello predice correttamente la classe positiva (negativa)*, mentre un **FP (FN)** si ha quando il *modello predice in maniera non corretta* la classe positiva (negativa)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Accuratezza**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'**accuratezza** è la prima *metrica* che vedremo per la valutazione dei modelli di classificazione. Informalmente, possiamo definirla come la percentuale di predizioni corrette effettuate dal nostro modello, e definirla come:\n",
    "\n",
    "$$AC=\\frac{C}{T}$$\n",
    "\n",
    "dove $C$ è il numero totale di predizione corrette, mentre $T$ è il numero totale di predizioni. Nel caso della classificazione binaria, possiamo calcolare l'accuratezza come segue:\n",
    "\n",
    "$$AC=\\frac{TP+TN}{TP+TN+FP+FN}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immaginiamo ad esempio di aver ricevuto $100$  email, tra cui $10$ di spam. Il nostro spam detector ha individuato correttamente $5$ messaggi di spam, e classificato per $5$ sbaglio come spam  messaggi legittimi. Allora:\n",
    "\n",
    "$$AC=\\frac{TP+TN}{TP+TN+FP+FN}=\\frac{5+85}{5+85+5+5}$$\n",
    "\n",
    "In questo caso, l'**accuratezza** del modello è pari a $0.90$, o del $90%$, il che significa che il nostro modello è in grado di fare 90 predizioni su 100.Buon risultato, giusto?\n",
    "\n",
    "In realtà, non necessariamente. Infatti, delle mail che abbiamo ricevuto, $90$ sono legittime, e $10$ di spam. Questo significa che il modello è stato in grado di individuare *soltanto il $50%$ dello spam** ricevuto, ed ha inoltre classificato un buon $7%$ delle email legittime come spam. Tra cui, prevedibilmente, quella che ci comunicava notizie di vitale importanza. In sostanza, il nostro modello ha un'efficacia \"vera e propria\" al più in un caso su due.\n",
    "\n",
    "Di conseguenza, l'accuratezza non ci racconta \"tutta la storia\" quando lavoriamo su un dataset sbilanciato come questo, dove vi è una disparità significativa tra la classe positiva e quella negativa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'accuratezza delle predizioni effettuate da un classificatore è ottenuta in Scikit Learn utilizzando il metodo `accuracy_score()` del package `sklearn.metrics`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Precisione**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **precisione** è una metrica che prova a risolvere alcuni dei problemi dell'accuratezza valutando quale sia la *proporzione di valori per la classe positiva identificati correttamente*.\n",
    "\n",
    "La definizione analitica della precisione è la seguente:\n",
    "\n",
    "$$P=\\frac{TP}{TP+FP}$$\n",
    "\n",
    "In pratica, riferendoci al nostro solito esempio, la precisione è data dal rapporto tra le mail di spam riconosciute come tali e la somma tra queste e le mail legittime riconosciute come spam. Provando a calcolarla:\n",
    "\n",
    "$$P=\\frac{TP}{TP+FP} = \\frac{5}{5+5}=0.5$$\n",
    "\n",
    "\n",
    "Il modello ha quindi una precisione del **$50\\%$** nel riconoscere una mail di spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La precisione delle predizioni effettuate da un classificatore è ottenuta in Scikit Learn utilizzando il metodo `precision_score()` del package `sklearn.metrics`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Recall**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il **recall**, traducibile in italiano come *richiamo*, verifica la *porzione di veri positivi correttamente identificata* dall'algoritmo, ed è espresso come:\n",
    "\n",
    "$$R=\\frac{TP}{TP+FN}$$\n",
    "\n",
    "Nel nostro caso, il recall sarà quindi dato dal rapporto tra le mail correttamente indicate come spam e la somma tra le stesse e quelle erroneamente indicate come legittime. Va da sè che anche in questo caso possiamo calcolarlo:\n",
    "\n",
    "$$R=\\frac{TP}{TP+FN}=\\frac{5}{5+5}=0.5$$\n",
    "\n",
    "Così come la precisione, il recall è pari al **$50\\%$**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il recall ha una rappresentazione in Scikit Learn mediante la funzione `recall_score()` del package `sklearn.metrics`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tuning della soglia di decisione**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per valutare l'effiacia del modello dobbiamo esaminare congiuntamente la **precisione** ed il **recall**.\n",
    "\n",
    "Sfortunatamente, questi due valori sono spesso in *contrapposizione*: spesso, infatti, migliorare la precisione riduce il recall, e viceversa. Per comprendere empiricamente questo concetto, facciamo un esempio con il nostro spam detector, immaginando di aver impostato la soglia di decisione a $0.6$.\n",
    "\n",
    "I risultati sono mostrati nella figura successiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![0.6](Images/06.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcoliamo la precisione e il recall in questo caso:\n",
    "\n",
    "$$P=\\frac{TP}{TP+FP} = \\frac{4}{4+1}=0.8$$\n",
    "\n",
    "$$R=\\frac{TP}{TP+FN}=\\frac{4}{4+2}=0.66$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proviamo ad **aumentare** la soglia di decisione, portandola al **$75\\%$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![0.75](Images\\075.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P=\\frac{TP}{TP+FP} = \\frac{3}{3}=1$$\n",
    "\n",
    "$$R=\\frac{TP}{TP+FN}=\\frac{3}{3+3}=0.5$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proviamo ad **diminuire** la soglia di decisione, portandola al **$50\\%$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![0.5](Images\\05.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P=\\frac{TP}{TP+FP} = \\frac{4}{4+3}=0.57$$\n",
    "\n",
    "$$R=\\frac{TP}{TP+FN}=\\frac{4}{4+2}=0.66$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come possiamo vedere, la **soglia di detection** agisce su *precisione e recall*.\n",
    "\n",
    "Non è però possibile aumentarli contemporaneamente, per cui occorre scegliere un valore tale per cui, ad esempio, si massimizzi la media.\n",
    "\n",
    "La realtà è che, però, dipende sempre dall'applicazione: se non abbiamo paura di perdere mail legittime, allora possiamo abbassare la soglia di decisione, aumentando il recall; viceversa, se siamo disposti ad eliminare manualmente un po' di spam, potremo alzare la soglia di decisione, aumentando la precisione."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Metriche per i regressori**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo brevemente alcune delle metriche che è possibile utilizzare per la valutazione delle performance di un *modello di regressione*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Mean Squared Error (MSE)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbiamo già visto questa metrica quando abbiamo parlato della regressione. L'**errore quadratico medio** è definito come:\n",
    "\n",
    "$$MSE = \\frac{1}{n}\\sum_{i=1}^n(y_i-\\hat{y_i})^2$$\n",
    "\n",
    "Questo errore, implementato in **Scikit Learn** dalla funzione `mean_squared_error()`, permette di tenere conto di eventuali errori negativi e positivi, ma viene influenzato dalla grandezza assoluta delle variabili.\n",
    "\n",
    "In altre parole, un errore dell'$1%$ su un valore $y=100$ sarà più influente di un errore del $50%$ su un valore $y=1$.\n",
    "\n",
    "Ovviamente, tanto è minore l'**MSE**, tanto è migliore il modello considerato."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Mean Absolute Percentage Error (MAPE)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il **mean absolute percentage error** viene calcolato mediante il rapporto tra il valore assoluto della differenza tra i valori veri e quelli predetti dal regressore e i valori veri stessi. \n",
    "\n",
    "Tale rapporto viene quindi mediato sull'insieme dei campioni, e ne viene dedotta la percentuale. La formula è la seguente:\n",
    "\n",
    "$$MAPE = \\frac{1}{n}\\sum_{i=1}^n \\frac{|y_i-\\hat{y_i}|}{max(\\epsilon,y_i)}\\%$$\n",
    "\n",
    "Il MAPE è implementato in **Scikit Learn** mediante la funzione `mean_average_percentage_error()`.\n",
    "\n",
    "Il vantaggio principale derivante dall'uso del MAPE sta nel fatto che l'uso del valore assoluto elimina eventuali annullamenti derivanti da contributi di segno opposto. Inoltre, la presenza del valore vero a denominatore fa in modo che la metrica sia sensibile agli errori relativi.\n",
    "\n",
    "Anche in questo caso, un valore di **MAPE** basso indica un'ottima approssimazione."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Esercizi**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Es 4.0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    classification_report,\n",
    "    mean_absolute_percentage_error,\n",
    "    mean_squared_error,\n",
    "    r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideriamo il regressore logistico usato nell'*Es 3.0* nel notebook \"[Apprendimento Supervisionato - Regressione Lineare e Logistica](https://github.com/marcocecca00/PythonCalcoloScientifico/blob/main/Notes/Modelli%20di%20Apprendimento%20Supervisionato.ipynb)\".\n",
    "\n",
    "Valutiamo per prima cosa i risultati ottenuti in termini di accuratezza, precisione e recall usando le apposite funzioni di Scikit Learn. Utilizziamo anche la funzione `classification_report()` per ottenere un report completo dell'esito del classificatore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento dei dati\n",
    "tips = sns.load_dataset('tips')\n",
    "X = tips.loc[:, ('total_bill', 'tip', 'size')].values\n",
    "y = tips.loc[:, ('day')].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addestramento del regressore logistico\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisione: 0.28\n",
      "Recall: 0.28\n",
      "Accuracy: 0.38\n"
     ]
    }
   ],
   "source": [
    "# Es 20.0 del notebook \"Apprendimento Supervisionato - Regressione Lineare e Logistica\"\n",
    "# Parte 1: metriche\n",
    "print('Precisione: {}'.format(round(precision_score(y_test, y_pred, average='macro'), 2)))\n",
    "print('Recall: {}'.format(round(recall_score(y_test, y_pred, average='macro'), 2)))\n",
    "print('Accuracy: {}'.format(round(accuracy_score(y_test, y_pred), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Fri       0.00      0.00      0.00         4\n",
      "         Sat       0.33      0.64      0.44        22\n",
      "         Sun       0.53      0.40      0.46        20\n",
      "        Thur       0.25      0.07      0.11        15\n",
      "\n",
      "    accuracy                           0.38        61\n",
      "   macro avg       0.28      0.28      0.25        61\n",
      "weighted avg       0.36      0.38      0.33        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parte 2: classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Es 4.1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proviamo adesso a verificare come variano i valori di accuratezza, precisione e recall per diversi valori della soglia di decisione. In tal senso:\n",
    "\n",
    "semplifichiamo il problema riducendolo ad una classificazione binaria, e quindi considerando come label la colonna time;\n",
    "utilizziamo il metodo `predict_proba(X)` del `LogisticRegressor()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = tips.loc[:, ('time')].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non abbiamo un *metodo diretto* per modificare il valore di soglia di decisione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_pred = clf.predict_proba(X_test)\n",
    "# Nota: considero soltanto i valori massimi per le predizioni\n",
    "preds = [np.amax(pred) for pred in probs_pred]\n",
    "y_pred = clf.predict(X_test)\n",
    "preds_cls = list(zip(list(y_pred), preds, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74 0.9024390243902439\n",
      "0.7692307692307693 0.4166666666666667\n",
      "0.7213114754098361 1.0\n"
     ]
    }
   ],
   "source": [
    "# Conto TP, TN, FP, FN\n",
    "def get_precision_recall_from_probs(probs, threshold=0.65):\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    for prob in probs:\n",
    "        if prob[1] > threshold and (prob[0] == prob[2]):\n",
    "            # Abbiamo un true positive\n",
    "            tp += 1\n",
    "        elif prob[1] > threshold and (prob[0] != prob[2]):\n",
    "            # Abbiamo un false positive\n",
    "            fp += 1\n",
    "        elif prob[1] <= threshold and (prob[0] == prob[2]):\n",
    "            # Abbiamo un true negative\n",
    "            tn += 1\n",
    "        elif prob[1] <= threshold and (prob[0] != prob[2]):\n",
    "            # Abbiamo un false negative\n",
    "            fn += 1\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    return precision, recall\n",
    "\n",
    "p_65, r_65 = get_precision_recall_from_probs(preds_cls)\n",
    "p_80, r_80 = get_precision_recall_from_probs(preds_cls, threshold=0.80)\n",
    "p_50, r_50 = get_precision_recall_from_probs(preds_cls, threshold=0.50)\n",
    "print(p_65, r_65)\n",
    "print(p_80, r_80)\n",
    "print(p_50, r_50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Es 4.2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideriamo il regressore lineare usato nell'esercizio 16.1. Valutiamo i risultati ottenuti in termini di **MSE**, **MAPE** ed $R^2$ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 0.28\n",
      "MSE: 1.04\n",
      "R2: 0.46\n"
     ]
    }
   ],
   "source": [
    "X = tips['total_bill'].values.reshape(-1, 1)\n",
    "y = tips['tip'].values.reshape(-1, 1)\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)\n",
    "y_pred = lin_reg.predict(X)\n",
    "print('MAPE: {}'.format(round(mean_absolute_percentage_error(y, y_pred), 2)))\n",
    "print('MSE: {}'.format(round(mean_squared_error(y, y_pred), 2)))\n",
    "print('R2: {}'.format(round(r2_score(y, y_pred), 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2024b47f9e0e00785bf7b410773834da4047a250e58841a8c9925163fbfa3efc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
