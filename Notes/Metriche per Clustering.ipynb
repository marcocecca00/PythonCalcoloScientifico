{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Metriche**\n",
    "## *Metriche di clustering*\n",
    "Definizione della metriche per il clustering: *adjusted rand index* ed il *silhouette score*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Adjusted Rand Index**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sia $C$ l'insieme dei cluster \"veri\" assegnati ad un certo dataset, e $K$ l'insieme dei cluster assegnati a valle dell'applicazione di un algoritmo di clustering. Allora definiamo l'**Indice di Rand** come:\n",
    "\n",
    "$$RI=\\frac{a+b}{C_2^n}$$\n",
    "\n",
    "dove:\n",
    "\n",
    "- $a$ è il numero di coppie di campioni che appartengono allo stesso cluster sia in $C$ sia a valle dell'assegnazione $K$;\n",
    "\n",
    "- $b$ è il numero di coppie di campioni che non appartengono allo stesso cluster sia in $C$ sia a valle dell'assegnazione $K$;\n",
    "\n",
    "- $C_2^n$ è il numero totale di coppie di campioni presenti nel dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si può dimostrare non è garantito che l'indice di Rand assuma valore vicino allo zero a seguito di un'assegnazione completamente casuale dei cluster da parte dell'algoritmo.\n",
    "\n",
    "Possiamo quindi tenere conto dell'aspettazione $E[RI]$ di ottenere un'assegnazione casuale mediante l'*indice di Rand modificato*:\n",
    "\n",
    "$$ARI=\\frac{RI-E[RI]}{max(RI)-E[RI]}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In **Scikit Learn**, l'indice di Rand modificato è ottenuto usando la funzione `adjusted_rand_score() ` del package metrics.\n",
    "\n",
    "Il valore ottimale dell'ARI è pari proprio ad 1, caso in cui il clustering è riuscito a predire correttamente tutte le classi dei singoli campioni. Valori prossimi allo zero o negativi (fino a -1) contraddistinguono invece labeling non corretti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una metrica di questo tipo ha l'ovvio vantaggio di essere facilmente interpretabile, oltre che di non essere collegata ad uno specifico algoritmo di clustering.\n",
    "\n",
    "Tuttavia, vi è una criticità indotta dalla necessità di **conoscere a priori il labeling** esatto dei campioni (il che, quindi, potrebbe farci propendere per l'uso di un algoritmo di classificazione)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Silhoutte Score**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A differenza dell'**ARI**, il **silhouette score** non richiede la *conoscenza aprioristica* delle label vere; per valutare la qualità del clustering, invece, questa metrica si affida a valutazioni sulla separazione dei cluster, ottenendo un valore tanto più alto quanto questi sono tra di loro ben separati e definiti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particolare, il silhouete score per un singolo campione è definito come:\n",
    "\n",
    "$$s=\\frac{b-a}{max(a,b)}$$\n",
    "\n",
    "dove:\n",
    "\n",
    "- $a$ è la distanza media tra un campione e tutti gli altri campioni appartenenti allo stesso cluster;\n",
    "- $b$ è la distanza media tra un campione e tutti gli altri campioni appartenenti al cluster più vicino."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questa metrica, implementata grazie alla funzione `silhouette_score()` del package `metrics`, è anch'essa di facile interpretazione, in quanto può assumere valori compresi nell'intervallo $[-1,1]$, con:\n",
    "\n",
    "- valori prossimi a $-1$ che indicano un clustering non corretto;\n",
    "- valori prossimi allo $0$ che indicano cluster sovrapposti;\n",
    "- valori prossimi a $+1$ che indicano cluster densi e ben suddivisi.\n",
    "\n",
    "Uno svantaggio del silhouette score è che, in generale, può variare in base all'algoritmo utilizzato."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Esercizi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import adjusted_rand_score, silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Es 7.0**\n",
    "\n",
    "Ricreiamo le condizioni sperimentali degli esercizi *Es 6.3* ed *Es 6.2*.\n",
    "\n",
    "Stavolta, però, valutiamo le performance di ogni algoritmo utilizzando l'ARI ed il silhouette score.\n",
    "\n",
    "Inoltre, proviamo a vedere cosa accade per i seguenti parametri:\n",
    "\n",
    "- per il K-Means, facciamo variare il numero di cluster tra `2` e `5`;\n",
    "- per il DBSCAN, assegnamo ad $\\epsilon$ i valori `0.5` o `1.0`, ed a `min_samples` i valori `5` e `10`.\n",
    "\n",
    "Per ognuno dei due algoritmi, infine, riportiamo a schermo solo i valori dei parametri per i quali le metriche assumono valore massimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_kmeans_results(X, y, use_case, verbose=False):\n",
    "    print(f'{use_case} - KMeans')\n",
    "    n_clusters_ari_best = 2\n",
    "    n_clusters_silhouette_best = 2\n",
    "    ari_best = 0\n",
    "    silhouette_best = 0\n",
    "    for n_clusters in range(2, 6):\n",
    "        kmeans = KMeans(n_clusters=n_clusters)\n",
    "        preds = kmeans.fit_predict(X)\n",
    "        ari = round(adjusted_rand_score(y, preds), 2)\n",
    "        silhouette = round(silhouette_score(X, preds), 2)\n",
    "        if verbose:\n",
    "            print(f'Numero di cluster: {n_clusters}')\n",
    "            print(f'ARI KMeans: {ari}')\n",
    "            print(f'Silhouette score KMeans: {silhouette}')\n",
    "        if ari > ari_best:\n",
    "            ari_best = ari\n",
    "            n_clusters_ari_best = n_clusters\n",
    "        if silhouette > silhouette_best:\n",
    "            silhouette_best = silhouette\n",
    "            n_clusters_silhouette_best = n_clusters\n",
    "    print(\n",
    "        f'''Parametri con il valore massimo di ARI:\n",
    "        num clusters: {n_clusters_ari_best}\n",
    "        Valore massimo di ARI: {ari_best}''')\n",
    "    print(\n",
    "        f'''Parametri con il valore massimo di silhouette:\n",
    "        num clusters: {n_clusters_silhouette_best}\n",
    "        Valore massimo di silhouette: {silhouette_best}''')\n",
    "\n",
    "\n",
    "def print_dbscan_results(X, y, use_case, verbose=False):\n",
    "    print(f'{use_case} - DBSCAN')\n",
    "    eps_mins_ari_best = [0, 0]\n",
    "    eps_mins_silhouette_best = [0, 0]\n",
    "    ari_best = 0\n",
    "    silhouette_best = 0\n",
    "    for epsilon in [0.5, 1.0]:\n",
    "        for min_samples in [5, 10]:\n",
    "            dbscan = DBSCAN(eps=epsilon, min_samples=min_samples)\n",
    "            preds = dbscan.fit_predict(X)\n",
    "            ari = round(adjusted_rand_score(y, preds), 2)\n",
    "            silhouette = round(silhouette_score(X, preds), 2)\n",
    "            if verbose:\n",
    "                print(f'Epsilon: {epsilon} - Min samples: {min_samples}')\n",
    "                print(f'ARI KMeans: {ari}')\n",
    "                print(f'Silhouette score KMeans: {silhouette}')\n",
    "            if ari > ari_best:\n",
    "                ari_best = ari\n",
    "                eps_mins_ari_best = [epsilon, min_samples]\n",
    "            if silhouette > silhouette_best:\n",
    "                silhouette_best = silhouette\n",
    "                eps_mins_silhouette_best = [epsilon, min_samples]\n",
    "    print(\n",
    "        f'''Parametri con il valore massimo di ARI:\n",
    "        eps: {eps_mins_ari_best[0]} - min samples: {eps_mins_ari_best[1]}\n",
    "        Valore massimo di ARI: {ari_best}''')\n",
    "    print(\n",
    "        f'''Parametri con il valore massimo di silhouette score:\n",
    "        eps: {eps_mins_silhouette_best[0]} - min samples: {eps_mins_silhouette_best[1]}\n",
    "        Valore massimo di silhouette: {silhouette_best}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster corretti - KMeans\n",
      "Parametri con il valore massimo di ARI:\n",
      "        num clusters: 3\n",
      "        Valore massimo di ARI: 1.0\n",
      "Parametri con il valore massimo di silhouette:\n",
      "        num clusters: 3\n",
      "        Valore massimo di silhouette: 0.84\n",
      "Cluster corretti - DBSCAN\n",
      "Parametri con il valore massimo di ARI:\n",
      "        eps: 1.0 - min samples: 5\n",
      "        Valore massimo di ARI: 0.99\n",
      "Parametri con il valore massimo di silhouette score:\n",
      "        eps: 1.0 - min samples: 5\n",
      "        Valore massimo di silhouette: 0.82\n"
     ]
    }
   ],
   "source": [
    "X, y = make_blobs(n_samples=1000, random_state=42)\n",
    "\n",
    "print_kmeans_results(X, y, 'Cluster corretti')\n",
    "print_dbscan_results(X, y, 'Cluster corretti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster anisotropi - KMeans\n",
      "Parametri con il valore massimo di ARI:\n",
      "        num clusters: 3\n",
      "        Valore massimo di ARI: 0.99\n",
      "Parametri con il valore massimo di silhouette:\n",
      "        num clusters: 2\n",
      "        Valore massimo di silhouette: 0.82\n",
      "Cluster anisotropi - DBSCAN\n",
      "Parametri con il valore massimo di ARI:\n",
      "        eps: 1.0 - min samples: 5\n",
      "        Valore massimo di ARI: 1.0\n",
      "Parametri con il valore massimo di silhouette score:\n",
      "        eps: 1.0 - min samples: 5\n",
      "        Valore massimo di silhouette: 0.74\n"
     ]
    }
   ],
   "source": [
    "# Ipotesi 1: anisotropia\n",
    "t = np.tan(np.radians(60))\n",
    "rot = np.array([[1, t], [0, 1]])\n",
    "X_an = X.dot(rot)\n",
    "\n",
    "print_kmeans_results(X_an, y, 'Cluster anisotropi')\n",
    "print_dbscan_results(X_an, y, 'Cluster anisotropi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster a diversa varianza - KMeans\n",
      "Parametri con il valore massimo di ARI:\n",
      "        num clusters: 3\n",
      "        Valore massimo di ARI: 0.75\n",
      "Parametri con il valore massimo di silhouette:\n",
      "        num clusters: 3\n",
      "        Valore massimo di silhouette: 0.49\n",
      "Cluster a diversa varianza - DBSCAN\n",
      "Parametri con il valore massimo di ARI:\n",
      "        eps: 0.5 - min samples: 5\n",
      "        Valore massimo di ARI: 0.32\n",
      "Parametri con il valore massimo di silhouette score:\n",
      "        eps: 1.0 - min samples: 5\n",
      "        Valore massimo di silhouette: 0.31\n"
     ]
    }
   ],
   "source": [
    "# Ipotesi 2: diversa varianza\n",
    "X_var, y_var = make_blobs(\n",
    "    n_samples=1000,\n",
    "    random_state=200,\n",
    "    cluster_std=[1.8, 2.5, 2.4])\n",
    "\n",
    "print_kmeans_results(X_var, y_var, 'Cluster a diversa varianza')\n",
    "print_dbscan_results(X_var, y_var, 'Cluster a diversa varianza')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster a diversa cardinalità - KMeans\n",
      "Parametri con il valore massimo di ARI:\n",
      "        num clusters: 3\n",
      "        Valore massimo di ARI: 0.75\n",
      "Parametri con il valore massimo di silhouette:\n",
      "        num clusters: 3\n",
      "        Valore massimo di silhouette: 0.49\n",
      "Cluster a diversa cardinalità - DBSCAN\n",
      "Parametri con il valore massimo di ARI:\n",
      "        eps: 0.5 - min samples: 5\n",
      "        Valore massimo di ARI: 0.32\n",
      "Parametri con il valore massimo di silhouette score:\n",
      "        eps: 1.0 - min samples: 5\n",
      "        Valore massimo di silhouette: 0.31\n"
     ]
    }
   ],
   "source": [
    "# Ipotesi 3: diversa cardinalità\n",
    "X, y = make_blobs(n_samples=1000, random_state=12)\n",
    "X_uneven = np.concatenate(\n",
    "    (X[y == 0][:200], X[y == 1][:50], X[y == 2][:10]),\n",
    "    axis=0)\n",
    "y_uneven = np.concatenate(\n",
    "    (y[y == 0][:200], y[y == 1][:50], y[y == 2][:10]),\n",
    "    axis=0)\n",
    "\n",
    "print_kmeans_results(X_var, y_var, 'Cluster a diversa cardinalità')\n",
    "print_dbscan_results(X_var, y_var, 'Cluster a diversa cardinalità')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2024b47f9e0e00785bf7b410773834da4047a250e58841a8c9925163fbfa3efc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
