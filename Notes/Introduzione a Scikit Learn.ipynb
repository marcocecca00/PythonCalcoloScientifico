{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduzione a Scikit Learn**\n",
    "## *Stimatori, Transformer e Preprocessing*\n",
    "Breve introduzione all'uso della libreria *Scikit Learn* con *Esercizi*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scikit Learn** √® una tra le librerie per il machine learning pi√π utilizzate in Python. Ci√≤ avviene principalmente per tre fattori:\n",
    "\n",
    "- il supporto ad un numero molto elevato di algoritmi di machine learning.\n",
    "- la semplicit√† di utilizzo della libreria.\n",
    "- la perfetta integrazione con NumPy e Pandas.\n",
    "\n",
    "Partiamo quindi nella nostra discussione sulla libreria da una panoramica ad ampio spettro delle potenzialit√† della stessa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Stimatori e Transformer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit Learn si basa su due concetti fondamentali, ovvero quelli di **estimator** (*stimatore*) e di **transformer** (*trasformatore di dati*).\n",
    "\n",
    "In particolare, un *estimator* √® l'implementazione di uno specifico algoritmo di machine learning, mentre un transformer √® un algoritmo che effettua delle trasformazioni sui dati.\n",
    "\n",
    "Ad esempio, le istanze delle classi `RandomForestClassifier` e `DBSCAN` sono degli *estimator*, mentre quelle della classe `StandardScaler` sono dei transformer.\n",
    "\n",
    "Questa suddivisione permette di implementare un'interfaccia comune, la quale offre nella maggior parte dei casi i metodi `fit()`,  `transform()` e `predict()`: rispettivamente *fit()* √® comune, mentre *transform* e *predict* rispettivamente sono usati per l'addestramento e la trasformazione dei dati.\n",
    "\n",
    "Tuttavia, √® importante notare come ogni stimatore e transformer abbiano **parametri specifici** e dipendenti dalla natura dell'algoritmo utilizzato. Ogni algoritmo, inoltre, andr√† verificato secondo delle opportune **metriche**, che permettono di definire, in termini percentuali o assoluti, l'**accuratezza** dell'algoritmo utilizzato."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbiamo visto come spesso sia necessario effettuare delle operazioni di **preprocessing** sui dati. In tal senso, gli strumenti che utilizzeremo maggiormente sono:\n",
    "\n",
    "- **Imputer**\n",
    "\n",
    "    Per asssegnare *valori mancanti*, come ad esempio gli oggetti di classe `SimpleImputer` o `IterativeImputer` o `KNNImputer`\n",
    "- **Scaler**\n",
    "\n",
    "    Per trasformare le *feature numeriche* come ad esempio gli oggetti di classe `MinMaxScaler` e `StandardScaler`.\n",
    "- **Enconder**\n",
    "\n",
    "    Per trasformare le *feature categoriche* come ad esempio gli oggetti di classe `OrdinalEncoder` e `OneHotEncoder` e `LabelEncoder`. Quest'ultimo funziona come l'*OrdinalEncoder*, ma agisce sulle label.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classe | Applicazione\n",
    ":-----: | :--------:\n",
    "**SimpleImputer**    | Assegna un valore ad una feature mancante sulla base degli altri valori della stessa, secondo una strategia ben definita (ad esempio, la media). \n",
    "**IterativeImputer**   | Assegna un valore ad una feature mancante come funzione dei valori assunti dalle altre feature. Tale valore √® assegnato usando un approccio di regressione (anche multivariata) tra le altre feature e la feature target.\n",
    "**KNNImputer**  | Il k-nearest neighbor utilizzato nel riconoscimento di pattern per la classificazione di oggetti basandosi sulle caratteristiche degli oggetti vicini a quello considerato\n",
    "**MinMaxScaler** | Normalizza i valori assunti dalle feature nel range che va tra un certo minimo ed un certo massimo\n",
    "**StandardScaler**   | Standardizza i valori assunti dalle feature in modo da farli distribuire secondo una gaussiana a media nulla e varianza unitaria (*Z-score*).\n",
    "**OrdinalEncoder**   | Codifica una feature categoriche in un range che va 0 ad ùëõ ‚àí 1, con ùëõ numero di possibili valori assunti dalla feature.\n",
    "**OneHotEncoder**    | Codifica una feature categorica mediante la tecnica del one hot encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Esercizi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Es 1.0**\n",
    "\n",
    "Analizziamo i dati del dataset Titanic, e prepariamoli per un'elaborazione successiva.\n",
    "\n",
    "In particolare, proviamo a:\n",
    "\n",
    "- *Rimuovere* le feature rumorose o non necessarie.\n",
    "- *Normalizzare* le feature numeriche nell'intervallo.\n",
    "- *Convertire* le feature categoriche in valori numerici."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importo il *DataSet* di interesse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('DataSet\\\\titanic.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Rimuovo* le features non necessarie, ossia *Name*, *Ticket*, *Cabin*, *SibSp*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age     Fare\n",
       "0         0       3    male  22.0   7.2500\n",
       "1         1       1  female  38.0  71.2833\n",
       "2         1       3  female  26.0   7.9250\n",
       "3         1       1  female  35.0  53.1000\n",
       "4         0       3    male  35.0   8.0500"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_retain = df.loc[:, ('Survived', 'Pclass', 'Sex', 'Age', 'Fare')]\n",
    "data_to_retain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passo a *convertire* le features categoriche e *normalizzare* le features numeriche utilizzando il metodo `fit_transform()` che contestualmente mi converte e normalizza la feature. Il valore di ritorno √® un *array NumPy*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived_encoder =  OrdinalEncoder()                    # Istanza della classe\n",
    "survived_encoded = survived_encoder.fit_transform(      # Trasforma e normalizza la feature categorica 'Survived'\n",
    "    data_to_retain['Survived'].values.reshape(-1,1)\n",
    ")\n",
    "\n",
    "pclass_encoder =  OrdinalEncoder()                      # Istanza della classe\n",
    "pclass_encoded = pclass_encoder.fit_transform(          # Trasforma e normalizza la feature categorica 'Pclass'\n",
    "    data_to_retain['Pclass'].values.reshape(-1,1)\n",
    ")    \n",
    "\n",
    "sex_encoder = OrdinalEncoder()                          # Istanza della classe\n",
    "sex_encoded = sex_encoder.fit_transform(                # Trasforma e normalizza la feature categorica 'Sex'\n",
    "    data_to_retain['Sex'].values.reshape(-1,1)\n",
    ")\n",
    "\n",
    "age_scaler = MinMaxScaler()                             # Istanza della classe\n",
    "age_scaled = age_scaler.fit_transform(                  # Trasforma e normalizza la feature numerica 'Age'\n",
    "    data_to_retain['Age'].values.reshape(-1,1)\n",
    ")\n",
    "\n",
    "fare_scaler = MinMaxScaler()                             # Istanza della classe\n",
    "fare_scaled = age_scaler.fit_transform(                  # Trasforma e normalizza la feature numerica 'Fare'\n",
    "    data_to_retain['Fare'].values.reshape(-1,1)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adesso colleziono gli array trasformati in un singolo *array concatenato* e creo un nuovo *DataFrame*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.014151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472229</td>\n",
       "      <td>0.139136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.015469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.103644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.015713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.334004</td>\n",
       "      <td>0.025374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.233476</td>\n",
       "      <td>0.058556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.045771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.058556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.396833</td>\n",
       "      <td>0.015127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex       Age      Fare\n",
       "0         0.0     2.0  1.0  0.271174  0.014151\n",
       "1         1.0     0.0  0.0  0.472229  0.139136\n",
       "2         1.0     2.0  0.0  0.321438  0.015469\n",
       "3         1.0     0.0  0.0  0.434531  0.103644\n",
       "4         0.0     2.0  1.0  0.434531  0.015713\n",
       "..        ...     ...  ...       ...       ...\n",
       "886       0.0     1.0  1.0  0.334004  0.025374\n",
       "887       1.0     0.0  0.0  0.233476  0.058556\n",
       "888       0.0     2.0  0.0       NaN  0.045771\n",
       "889       1.0     0.0  1.0  0.321438  0.058556\n",
       "890       0.0     2.0  1.0  0.396833  0.015127\n",
       "\n",
       "[891 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = np.concatenate((\n",
    "    survived_encoded,\n",
    "    pclass_encoded,\n",
    "    sex_encoded,\n",
    "    age_scaled,\n",
    "    fare_scaled\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "pd.DataFrame(\n",
    "    new_data,\n",
    "    columns = ['Survived', 'Pclass', 'Sex', 'Age', 'Fare']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2024b47f9e0e00785bf7b410773834da4047a250e58841a8c9925163fbfa3efc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
